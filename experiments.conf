# Chinese model configuration.

bert_base_chinese {
  # Edit this
  data_dir = ./data
  
  # Computation limits.
  max_top_antecedents = 50
  max_training_sentences = 11
  top_span_ratio = 0.4
  max_num_speakers = 20
  max_segment_len = 128

  # Learning
  bert_learning_rate = 1e-05
  task_learning_rate = 0.0002
  adam_eps = 1e-6
  dropout_rate = 0.3
  
  # Task choice
  num_docs = 1810
  num_epochs = 30
  do_train = true
  do_eval = true
  do_test = true
  do_one_example_test = true
  eval_frequency = 5000
  report_frequency = 10

  # Model hyperparameters.
  genres = ["bc", "bn", "mz", "nw", "tc", "wb"]
  coref_depth = 2
  ffnn_size = 2000
  feature_size = 20
  max_span_width = 30
  use_metadata = true
  use_features = true
  use_segment_distance = true
  model_heads = false
  fine_grained = true
  use_prior = true
  single_example = true

  # file path
  train_path = ${data_dir}/train/train.chinese.128.jsonlines
  eval_path = ${data_dir}/dev/dev.chinese.128.jsonlines
  test_path = ${data_dir}/test/test.chinese.128.jsonlines
  test_output_path = ${data_dir}/test_result.jsonlines
  online_output_path = ${data_dir}/online_test_result.jsonlines
  conll_eval_path = ${data_dir}/dev/dev.chinese.v4_gold_conll
  conll_test_path= ${data_dir}/test/test.chinese.v4_gold_conll
  model_save_path = ./trained_coref_model
  pretrained_model = ./pretrain_model/
  vocab_file = ./pretrain_model/vocab.txt
  bert_config_file = ./pretrain_model/bert_config.json
}